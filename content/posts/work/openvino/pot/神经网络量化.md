---
tags: []
categories: ["work"]
description:
summary:
draft: false
isCJKLanguage: true
date: "2022-06-02"
lastmod: "2022-06-07"
title: 神经网络量化
---

# 神经网络量化

**量化目的**：减小模型体积，加速推理过程

工业界：FP32 在推理（inference）期间被 INT8 取代，而训练（training）仍然是 FP32

 在深度神经网络中模型参数存储为浮点值，模型的前向传播涉及一系列浮点运算。所以对于深度学习量化是指对精度要求较低的数据类型中的权重和激活进行量化

## 量化分类

> [!cite] 参考
> [深度学习模型量化（低精度推理）大总结](https://blog.csdn.net/zlgahu/article/details/104662203?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5.control)

### 原理分类

#### 对称量化

对称量化的基本思路是通过一个收缩因子（scale）将 FP32 tensor 中的最大绝对值映射到 8-bit 数据的最大值，将最大绝对值的负值映射到 8-bit 数据的最小值

![](https://s2.loli.net/2022/06/06/7sd9BiRYkOJ5C2N.png)

#### 非对称量化

非对称量化的基本思想是通过 收缩因子（scale） 和 零点（zero point） 将 FP32 张量 的 min/max 映射分别映射到 8-bit 数据的 min/max

![](https://s2.loli.net/2022/06/06/IuwOnvt3kfgyNFQ.png)

非对称量化与对称量化相比能更好地处理数据分布不均匀的情况

### 算法分类

> [!cite] 参考
> [神经网络压缩方法：模型量化的概念简介](https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/122272579)

#### 训练后量化

在这种方法中，量化是在模型完全训练后执行的。由于权重在训练后是固定的权重的映射很容易计算，因为层的激活值根据传递的输入张量而变化， 所以在训练后计算激活范围就比较麻烦，这里有两种处理方法：

##### 动态训练后量化

这涉及根据运行时输入到模型的数据分布，在推理过程中动态微调激活范围。这种方法最容易实现，因为量化不需要额外的步骤。由于不需要额外的数据，这种方法最适合难以生成详尽数据分布的情况——例如：序列到序列模型。但是在运行时使用指数移动平均线来估计激活范围会增加模型延迟。

##### 静态训练后量化

这种方法会涉及额外的校准步骤，例如使用代表性数据集来估计使数据集变化的激活范围。为保证最大程度地减少误差，这种估计会以全精度数据进行，然后将激活按比例缩小到较低精度的数据类型。由于在运行期间的推理过程中没有进行额外的计算，因此这种方法生成的模型速度最快（延迟最少）。

使用训练后量化的主要优点是不需要在整个数据集上进行训练，8 位或 16 位量化可以应用于任何现有的预训练模型。像 Pytorch 和 Tensorflow 这样的现代深度学习框架对这些方法都有官方实现。但是这种策略会由于量化误差而导致一些（通常是轻微的）精度损失。

#### 量化感知训练

量化感知训练 (QAT) 试图解决由于模型训练过程中的量化误差而导致的精度损失的问题。在前向传递中 QAT 在权重和激活计算期间复制量化行为，而损失计算和损失的反向传播保持不变（保持更高的精度）。

##### 自动混合精度量化

作为 QAT 的扩展，在某些情况下仍不可能将某些层的输入域的整个范围完全拟合到较低精度的量化范围中。这种情况下使用更高的精度值保留这些层是有益的。随着自动混合精度训练的引入这一问题在很大程度上得到了解决，自动混合精度训练涉及到在训练时间内根据层的激活范围来确定单个层的量化，并且对模型的精度没有影响。

## 量化原理（非对称量化）

> [!cite] 参考
>[神经网络量化入门--基本原理 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/149659607)

由 float32 到 int8 的量化公式：$$Q=\frac{R}{S}+Z$$
由 int8 到 float32 的量化公式：$$Q=round(\frac{R}{S}+Z)$$

R：真实浮点值
Q：量化后定点值
S：浮点数与整数间的比例关系
Z：浮点值 0 量化后的定点值

S 和 Z 的计算方法：$$S=\frac{r_{max}-r_{min}}{q_{max}-q{min}}$$$$Z=round(q_{max}-\frac{r_{max}}{S})$$

[Tensorflow模型量化(Quantization)原理及其实现方法_爱问西瓜爱大树的博客-CSDN博客_tensorflow量化](https://blog.csdn.net/u011208984/article/details/106258949)
[tensorflow实现quantization-aware training（伪量化，fake quantization）_lishanlu136的博客-CSDN博客_伪量化节点](https://blog.csdn.net/lishanlu136/article/details/88872266)