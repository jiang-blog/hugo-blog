---
tags: []
categories: ["work", "openvino_pot"]
description:
summary:
draft: false
isCJKLanguage: true
date: "2022-05-26"
lastmod: "2022-06-10"
title: 1-2-精度感知量化模型
---

# 1-2-精度感知量化模型

## 简介

本文假设您已经对同一模型进行了[默认量化](1-1_量化模型.md)。如果它引入了显著的精度下降，可以使用精度感知量化算法来保持精度在预定义的范围内。与[默认量化](1-1_量化模型.md)算法相比，这可能会导致性能下降，因为一些层可能会恢复到原来的精度。

> **注意事项**
> 在GNA target_device的情况下，精度感知量化算法的行为是不同的。它正在为每层的权重在INT8和INT16精度之间搜索最佳配置。该算法只对性能预设起作用。对于精度预设，这个算法没有帮助，因为整个模型已经是INT16精度了。

精度感知量化的脚本包括四个步骤:

1. 准备好数据和数据集接口
2. 定义精度度量
3. 选择量化参数
4. 定义并运行量化过程

## 准备数据和数据集接口

这一步与[[1-1_量化模型|默认量化]]的情况相同。唯一的区别是_`_getitem__()`方法应该返回`(data, annotation)`或`(data, annotation,metadata)`，其中`annotation`是必需的，其格式应该符合`Metrc`类的期望。`metadata`是一个可选的字段，可以用来存储后期处理所需的额外信息。

## 定义精度度量

为了在优化过程中控制精度，应该实现`openvino.tools.pot.Metric`接口。每个实现都应该覆盖以下属性：

- `value` - 以`Dict[str, numpy.array]`的格式返回最后一个模型输出的精度指标值。
- `avg_value` - 以`Dict[str, numpy.array]`的格式返回所收集的模型结果的平均精度指标。
- `higher_better` - 如果指标的值越高，性能越好，则应返回`True`，否则返回`False`。默认实现返回`True`。

和方法：

- `update(output, annotation)` - 使用最后的模型输出和注释来计算和更新精度指标值。模型输出和注释应该被传递到这个方法中。在模型返回原始输出的情况下，它还应该包含模型特定的后处理。

- `reset()` - 重置收集的精度指标。

- `get_attributes()` - 返回一个公制属性的字典：
  ```python
  {metric_name: {attribute_name: value}}。
  ```
  必要的属性：
  - `direction` - (`higher-better` 或 `higher-worse`)一个字符串参数，定义在精度感知算法中是否应该增加度量值。
  - `type` - 公制类型的字符串表示。例如，`accuracy` 或 `mean_iou`。

下面是一个用POT API实现accuracy top-1度量的例子:

```python
from openvino.tools.pot import Metric

class Accuracy(Metric):

    # Required methods
    def __init__(self, top_k=1):
        super().__init__()
        self._top_k = top_k
        self._name = 'accuracy@top{}'.format(self._top_k)
        self._matches = [] # container of the results

    @property
    def value(self):
        """ Returns accuracy metric value for all model outputs. """
        return {self._name: self._matches[-1]}

    @property
    def avg_value(self):
        """ Returns accuracy metric value for all model outputs. """
        return {self._name: np.ravel(self._matches).mean()}

    def update(self, output, target):
        """ Updates prediction matches.
        :param output: model output
        :param target: annotations
        """
        if len(output) > 1:
            raise Exception('The accuracy metric cannot be calculated '
                            'for a model with multiple outputs')
        if isinstance(target, dict):
            target = list(target.values())
        predictions = np.argsort(output[0], axis=1)[:, -self._top_k:]
        match = [float(t in predictions[i]) for i, t in enumerate(target)]

        self._matches.append(match)

    def reset(self):
        """ Resets collected matches """
        self._matches = []

    def get_attributes(self):
        """
        Returns a dictionary of metric attributes {metric_name: {attribute_name: value}}.
        Required attributes: 'direction': 'higher-better' or 'higher-worse'
                             'type': metric type
        """
        return {self._name: {'direction': 'higher-better',
                             'type': 'accuracy'}}
```

`Metric`实现的一个实例应该被传递给负责模型推理的`IEEngine`对象。

```python
metric = Accuracy()
engine = IEEngine(config=engine_config, data_loader=data_loader, metric=metric)
```

## 选择量化参数

准确度感知量化在初始化步骤中使用了默认量化算法，因此后者的所有参数也同样有效且可以被指定。这里，我们只描述Accuracy-aware Quantization所需的参数：

- `"maximal_drop"` - 量化后必须实现的最大精度下降。默认值为0.01（1%）。

## 运行量化

下面的代码例子显示了一个带有精度控制的基本量化工作流程。`UserDataLoader()`是`DataLoader`的实现的一个占位符。

```python
from openvino.tools.pot import IEEngine
from openvino.tools.pot load_model, save_model
from openvino.tools.pot import compress_model_weights
from openvino.tools.pot import create_pipeline

# Model config specifies the model name and paths to model .xml and .bin file
model_config = Dict(
    {
        "model_name": "model",
        "model": path_to_xml,
        "weights": path_to_bin,
    }
)

# Engine config
engine_config = Dict({"device": "CPU"})

algorithms = [
    {
        "name": "AccuracyAwareQuantization",
        "params": {
            "target_device": "ANY",
            "stat_subset_size": 300,
            'maximal_drop': 0.02
        },
    }
]

# Step 1: implement and create user's data loader
data_loader = UserDataLoader()

# Step 2: implement and create user's data loader
metric = Accuracy()

# Step 3: load model
model = load_model(model_config=model_config)

# Step 4: Initialize the engine for metric calculation and statistics collection.
engine = IEEngine(config=engine_config, data_loader=data_loader, metric=metric)

# Step 5: Create a pipeline of compression algorithms and run it.
pipeline = create_pipeline(algorithms, engine)
compressed_model = pipeline.run(model=model)

# Step 6 (Optional): Compress model weights to quantized precision
#                    in order to reduce the size of the final .bin file.
compress_model_weights(compressed_model)

# Step 7: Save the compressed model to the desired path.
# Set save_path to the directory where the model should be saved
compressed_model_paths = save_model(
    model=compressed_model,
    save_path="optimized_model",
    model_name="optimized_model",
)

# Step 8 (Optional): Evaluate the compressed model. Print the results.
metric_results = pipeline.evaluate(compressed_model)
```

值得注意的是，现在`Pipeline`对象中也有可以按需计算精度的`evaluate`方法。

如果精度感知量化不能实现所需的精度-性能权衡，建议尝试[NNCF](https://docs.openvino.ai/latest/docs_nncf_introduction.html#doxid-docs-nncf-introduction)的量化感知训练。

## 示例

- 对物体检测模型进行量化，控制精度
