---
tags: []
categories: ["work", "openvino_pot"]
description:
summary:
draft: false
isCJKLanguage: true
date: "2022-05-24"
lastmod: "2022-06-10"
title: 1-训练后优化模型
---

# 1-训练后优化模型

## 简介

训练后的模型优化是在不对模型进行重新训练或微调的情况下应用特殊方法的过程，例如，训练后的 8 位量化处理。因此，这个过程不需要训练数据集或源 DL 框架中的训练管道。为了在 OpenVINO 中应用后期训练方法，需要：

- 一个浮点精度的模型，FP32 或 FP16，转换为 OpenVINO 中间表示（IR）格式，并在 CPU 上用 OpenVINO 运行。

- 一个代表用例场景的代表性校准数据集，例如，300 个样本。

- 在精度受限的情况下，应该有一个验证数据集和精度指标。

为了满足训练后优化的需要，OpenVINO 提供了一个训练后优化工具（POT），支持统一整数量化方法。这种方法可以大幅提高推理性能，减少模型大小。

下图显示了使用 POT 的优化工作流程：

![](https://raw.githubusercontent.com/jiang-blog/BlogImgs/picgo/imgs/the%20optimization%20workflow%20with%20POT.png)

## 用 POT 对模型进行量化

POT 提供了两种主要的量化方法，可以根据用户的需要和要求来使用。

[默认量化](1-1_量化模型.md)是一种推荐的方法，在大多数情况下提供快速和准确的结果。它只需要一个未经注释的数据集来进行量化。详情请见[默认量化算法](1-1-1_默认量化算法.md)的文档。

[精度感知量化](1-2_精度感知量化模型.md)是一种先进的方法，可以在默认量化不能保证精度的情况下，以提高性能为代价，将精度保持在一个预定的范围。该方法需要有注释的代表性数据集，并且可能需要更多的时间进行量化。详情请见 "[精度感知量化算法](1-2-1_精度感知量化算法.md) " 文档。

硬件平台支持不同的整数精度和量化参数，例如 CPU、GPU、VPU 的 8 位，GNA 的 16 位。POT 通过引入一个 " 目标设备 " 的概念来抽象出这种复杂性，该概念用于设置特定于设备的量化设置。`target_device` 参数就是用于此目的。

```ad-note
title:注意事项
有一个特殊的target_device。"ANY"，它导致与CPU、GPU和VPU设备兼容的便携式量化模型。GNA量化的模型只与CPU兼容。
```

对于用 POT 工具优化的模型收集的基准测试结果，请参考 INT8 与 FP32 在特定网络和平台上的比较。

## 另见

[性能基准测试](https://docs.openvino.ai/latest/openvino_docs_performance_benchmarks_openvino.html)

[通过使用DL工作台的基于网络的界面进行INT8量化](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Int_8_Quantization.html)
